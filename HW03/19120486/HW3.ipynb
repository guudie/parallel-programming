{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGBgThS8q8k3"
      },
      "source": [
        "Họ tên: Nguyễn Trung Dũng\n",
        "\n",
        "MSSV: 19120486"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qdrvDrCrnqz"
      },
      "source": [
        "# HW3: Các loại bộ nhớ trong CUDA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKXB0wA7yhq9"
      },
      "source": [
        "Với các GPU tương đối mới thì để biên dịch chỉ cần dùng câu lệnh: \\\n",
        "`nvcc tên-file.cu -o tên-file-chạy`\n",
        "\n",
        "Nhưng trên Colab mình thường lấy được GPU khá cũ là Tesla K80 với compute capability (phiên bản phần cứng) là 3.7; để biên dịch đúng với GPU khá cũ này thì bạn cần dùng câu lệnh: \\\n",
        "`nvcc -arch=sm_37 tên-file.cu -o tên-file-chạy` \\\n",
        "Trong đó, 37 chính là compute capability của GPU Tesla K80.\n",
        "\n",
        "Để phòng trường hợp khi làm bài bạn lấy được GPU có compute capability x.x nhưng khi chấm bài Thầy lại lấy được GPU có compute capability khác x.x, dưới đây mình sẽ có đoạn code Python để tự động lấy 2 con số ứng với compute capability của GPU và lưu vào 2 biến `major` và `minor`:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCkmnirl2xWF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "077925b9-7dff-4eed-94e7-7902533750f2"
      },
      "source": [
        "from numba import cuda\n",
        "major, minor = cuda.get_current_device().compute_capability\n",
        "print(f'GPU compute capability: {major}.{minor}')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU compute capability: 7.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tq1-pmi72yS6"
      },
      "source": [
        "Một khi đã chạy đoạn code Python ở trên, để biên dịch thì bạn sẽ dùng câu lệnh: \\\n",
        "`nvcc -arch=sm_{major}{minor} tên-file.cu -o tên-file-chạy`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xCyT0o8Z7nj"
      },
      "source": [
        "Dưới đây, khi làm bài thì bạn có thể tùy ý thêm/xóa cell. Đừng xóa mấy cell có chữ của Thầy là được."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbFLx1i4JxIE"
      },
      "source": [
        "!nvcc -arch=sm_{major}{minor} HW3.cu -o HW3"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZNqZuECjNso",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c1e83fa-e5fa-400f-8745-cc4b74de0406"
      },
      "source": [
        "!./HW3 in.pnm out.pnm 32 32"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**********GPU info**********\n",
            "Name: Tesla T4\n",
            "Compute capability: 7.5\n",
            "Num SMs: 40\n",
            "Max num threads per SM: 1024\n",
            "Max num warps per SM: 32\n",
            "GMEM: 15843721216 bytes\n",
            "CMEM: 65536 bytes\n",
            "L2 cache: 4194304 bytes\n",
            "SMEM / one SM: 65536 bytes\n",
            "****************************\n",
            "\n",
            "Image size (width x height): 512 x 512\n",
            "\n",
            "Kernel 1, block size 32x32, grid size 16x16\n",
            "Kernel time: 0.350240 ms\n",
            "Error: 0.000703\n",
            "\n",
            "Kernel 2, block size 32x32, grid size 16x16\n",
            "Kernel time: 0.349216 ms\n",
            "Error: 0.000703\n",
            "\n",
            "Kernel 3, block size 32x32, grid size 16x16\n",
            "Kernel time: 0.266208 ms\n",
            "Error: 0.000703\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVFUj14OYUyy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a31ca37-bcb6-49dd-8bb6-63fee6c1b9bf"
      },
      "source": [
        "!./HW3 in.pnm out.pnm 16 16"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**********GPU info**********\n",
            "Name: Tesla T4\n",
            "Compute capability: 7.5\n",
            "Num SMs: 40\n",
            "Max num threads per SM: 1024\n",
            "Max num warps per SM: 32\n",
            "GMEM: 15843721216 bytes\n",
            "CMEM: 65536 bytes\n",
            "L2 cache: 4194304 bytes\n",
            "SMEM / one SM: 65536 bytes\n",
            "****************************\n",
            "\n",
            "Image size (width x height): 512 x 512\n",
            "\n",
            "Kernel 1, block size 16x16, grid size 32x32\n",
            "Kernel time: 0.461376 ms\n",
            "Error: 0.000703\n",
            "\n",
            "Kernel 2, block size 16x16, grid size 32x32\n",
            "Kernel time: 0.319616 ms\n",
            "Error: 0.000703\n",
            "\n",
            "Kernel 3, block size 16x16, grid size 32x32\n",
            "Kernel time: 0.247776 ms\n",
            "Error: 0.000703\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./HW3 in.pnm out.pnm 16 32"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0CapcbX-whw4",
        "outputId": "1a19860a-dd59-43b6-ab70-0c6e6b70e917"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**********GPU info**********\n",
            "Name: Tesla T4\n",
            "Compute capability: 7.5\n",
            "Num SMs: 40\n",
            "Max num threads per SM: 1024\n",
            "Max num warps per SM: 32\n",
            "GMEM: 15843721216 bytes\n",
            "CMEM: 65536 bytes\n",
            "L2 cache: 4194304 bytes\n",
            "SMEM / one SM: 65536 bytes\n",
            "****************************\n",
            "\n",
            "Image size (width x height): 512 x 512\n",
            "\n",
            "Kernel 1, block size 16x32, grid size 32x16\n",
            "Kernel time: 0.471072 ms\n",
            "Error: 0.000703\n",
            "\n",
            "Kernel 2, block size 16x32, grid size 32x16\n",
            "Kernel time: 0.315936 ms\n",
            "Error: 0.000703\n",
            "\n",
            "Kernel 3, block size 16x32, grid size 32x16\n",
            "Kernel time: 0.245920 ms\n",
            "Error: 0.000703\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./HW3 in.pnm out.pnm 45 22"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OS9ekZq4uET",
        "outputId": "84decdd2-1c2a-4b69-b5e0-b2fbcf923070"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**********GPU info**********\n",
            "Name: Tesla T4\n",
            "Compute capability: 7.5\n",
            "Num SMs: 40\n",
            "Max num threads per SM: 1024\n",
            "Max num warps per SM: 32\n",
            "GMEM: 15843721216 bytes\n",
            "CMEM: 65536 bytes\n",
            "L2 cache: 4194304 bytes\n",
            "SMEM / one SM: 65536 bytes\n",
            "****************************\n",
            "\n",
            "Image size (width x height): 512 x 512\n",
            "\n",
            "Kernel 1, block size 45x22, grid size 12x24\n",
            "Kernel time: 0.427904 ms\n",
            "Error: 0.000703\n",
            "\n",
            "Kernel 2, block size 45x22, grid size 12x24\n",
            "Kernel time: 0.346848 ms\n",
            "Error: 0.000703\n",
            "\n",
            "Kernel 3, block size 45x22, grid size 12x24\n",
            "Kernel time: 0.272640 ms\n",
            "Error: 0.000703\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XebMjR45-0Io"
      },
      "source": [
        "Có thể thấy khi dùng SMEM (kernel 2) thì hầu như là nhanh hơn so với khi không dùng SMEM (kernel 1) và khi kết hợp với CMEM (kernel 3) thì thời gian chạy cũng rút ngắn đáng kể so với kernel 1 và 2. <br/>\n",
        "Trong kernel 1, ta thấy mỗi thread phải truy xuất GMEM (mảng `inPixels`) nhiều lần, làm giảm tốc độ. <br/>\n",
        "Khi dùng SMEM thì ta có thể giảm số lân phải truy xuất GMEM bằng cách đọc 1 lần và lưu các phần tử phải truy xuất giá trị nhiều lần xuống bộ nhớ SMEM; hơn nữa, SMEM có tốc độ truy xuất nhanh hơn rất nhiều so với DRAM nên giảm thời gian chạy so với khi không dùng SMEM. <br/>\n",
        "CMEM tăng tốc kernel theo cách tương tự như SMEM. Trong kernel 1 và 2, mảng `d_filter` được lưu ở GMEM; trong kernel 3 thì mảng `dc_filter` là thuộc CMEM, và vì có kích thước < 8KB nên chương trình có thể tận dụng bộ nhớ constant cache, có tốc độ truy xuất nhanh hơn DRAM."
      ]
    }
  ]
}